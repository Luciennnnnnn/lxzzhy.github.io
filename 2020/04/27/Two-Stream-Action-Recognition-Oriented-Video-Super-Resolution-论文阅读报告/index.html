<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>Two-Stream Action Recognition-Oriented Video Super-Resolution 论文阅读报告 | Sienna's blog.</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/2.0.4/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/2.1.4/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/2.1.4/toastr.min.css"><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Two-Stream Action Recognition-Oriented Video Super-Resolution 论文阅读报告</h1><a id="logo" href="/.">Sienna's blog.</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Two-Stream Action Recognition-Oriented Video Super-Resolution 论文阅读报告</h1><div class="post-meta">2020-04-27<span> | </span><span class="category"><a href="/categories/Super-Resolution/">Super Resolution</a></span></div><div class="post-content"><p><a href="https://arxiv.org/abs/1903.05577" target="_blank" rel="noopener">论文链接</a></p>
<p>第一篇关于超分辨率、行为识别的paper。</p>
<h2 id="要点："><a href="#要点：" class="headerlink" title="要点："></a>要点：</h2><ul>
<li>通常如图片、视频分析任务对输入有分辨率上的要求，但现实环境中，经常会存在一些低分辨率的采样，因此需要考虑利用超分辨率加强后续分析的效果。</li>
<li>通常的超分辨率实现是以visual quality(视觉质量)为标准进行训练的，但此类超分辨率算法的结果在视频分析任务如行为识别上并不好，因为往往超分辨率的结果是填充图像、视频帧中的细节，但一些细节对特定的任务并无帮助，甚至会导致更差的效果，因此基于特定任务的超分辨率实现是必要的。如在行为识别中，应该更关注于跟运动相关的部分。</li>
<li>为基于two-stream网络的行为识别设计的超分辨率实现。因为two-stream由两部分组成：一是Spatial Stream从各帧获得的需要的空间信息，二是Temporal Stream从Optical Flow中获取相应的时间信息(即一个二维矢量场用来近似运动场在图像平面的投影)。因此文中的超分辨率方案也由两部分组成：Spatial-oriented SR(SoSR)和emporal-oriented SR (ToSR)。</li>
</ul>
<h2 id="Optical-Flow"><a href="#Optical-Flow" class="headerlink" title="Optical Flow"></a>Optical Flow</h2><p>optical flow主要是基于两个假设<br>(1) 亮度恒定不变。<br>(2) 时间连续或运动是“小运动”。<br>于是可以得到基本约束方程：</p>
<script type="math/tex; mode=display">I(x, y, t)=\mathrm{I}(\mathrm{x}+\mathrm{dx}, \mathrm{y}+\mathrm{dy}, \mathrm{t}+\mathrm{dt}),</script><p>对右边泰勒展开：</p>
<script type="math/tex; mode=display">I(x, y, t)=\mathrm{I}(\mathrm{x}, \mathrm{y}, \mathrm{t})+\frac{\partial I}{\partial x} d x+\frac{\partial I}{\partial y} d y+\frac{\partial I}{\partial t} d t+\varepsilon,</script><p>忽略二阶无穷小项，两边同除$dt$可得</p>
<script type="math/tex; mode=display">\frac{\partial I}{\partial x} \frac{d x}{d t}+\frac{\partial I}{\partial y} \frac{d y}{d t}+\frac{\partial I}{\partial t} \frac{d t}{d t}=0.</script><p>令：<script type="math/tex">\mathrm{u}=\frac{d x}{d t}, v=\frac{d y}{d t},I_{x}=\frac{\partial I}{\partial x}, I_{y}=\frac{\partial I}{\partial y}, I_{t}=\frac{\partial I}{\partial t}</script><br>则有以下简写形式：</p>
<script type="math/tex; mode=display">I_{x} u+I_{y} v+I_{t}=0</script><p>$\left(u,v\right)$即是所求Optical Flow vector。</p>
<h2 id="Spatial-oriented-SR-SoSR-和emporal-oriented-SR-ToSR-。"><a href="#Spatial-oriented-SR-SoSR-和emporal-oriented-SR-ToSR-。" class="headerlink" title="Spatial-oriented SR(SoSR)和emporal-oriented SR (ToSR)。"></a>Spatial-oriented SR(SoSR)和emporal-oriented SR (ToSR)。</h2><ul>
<li>SoSR：让网络更关注于运动的对象。<br>  这部分主要是提了weighted MSE，用$\sqrt{u^2(p) + v^2(p)}$作为每个像素点的权系数，即对应帧在像素p的Optical Flow矢向量的欧几里得范数，于是在视频帧中，运动幅度大的对象所对应的像素就有更高的权值。<br>  最后，SoSR的loss如下，$\mathcal{L}_{\mathrm{Feature}},\mathcal{L}_{\mathrm{Adversarial}}$ 为两个常用的loss，feature loss的目的为最小化SR与HR图像的高阶特征之间的差，adversarial loss则是保证两者之间的分布尽量相似。<br>  最后：<script type="math/tex; mode=display">\mathcal{L}_{\mathrm{SoSR}}=\alpha \mathcal{L}_{\mathrm{WMSE}}+\beta \mathcal{L}_{\mathrm{Feature}}+\gamma \mathcal{L}_{\mathrm{Adversarial}}</script></li>
<li>ToSR：让生成的超分辨率帧具有时间上的连续性。<br>  同时考虑当前帧和下一帧，其实就是让两帧中的对象位置根据运动形成对应。这部分同样借助HR计算到的Optical Flow，令<script type="math/tex; mode=display">\tilde{I}_{t}(p)=\hat{I}_{t+1}\left(p+F_{t \rightarrow t+1}(p)\right)</script>  则$\tilde{I}_{t}(p)$代表的是，当前第$t$帧中第$p$个像素点在下一帧中对应的像素值（这里考虑的是生成的超分辨率图片）。有了这个，分别添加关于SR、HR的loss，让它们之间的F范数尽量小。即：$\mathcal{L}_{\text {warp-SR }}=\left|\hat{I}_{t}-\tilde{I}_{t}\right|_{F}^{2},\mathcal{L}_{\text {warp-HR }}=\left|I_{t}-\tilde{I}_{t}\right|_{F}^{2}$<br>  最后，loss函数如下：<script type="math/tex; mode=display">\mathcal{L}_{\mathrm{ToSR}}=\alpha \mathcal{L}_{\mathrm{SR}}+\beta \mathcal{L}_{\mathrm{warp}-\mathrm{SR}}+\gamma \mathcal{L}_{\mathrm{warp}-\mathrm{HR}},</script>  $\mathcal{L}_{\mathrm{SR}}=\left|I_{t}-\hat{I}_{t}\right|_{F}^{2}+\left|I_{t+1}-\hat{I}_{t+1}\right|_{F}^{2}$ ,使生成的超分辨率图像与高分辨率图像之间尽量接近。</li>
</ul>
</div><div class="tags"></div><div class="post-nav"><a class="pre" href="/2020/04/27/Network-Intrusion-Detection-Based-on-Semi-supervised-Variational-Auto-Encoder%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">Network Intrusion Detection Based on Semi-supervised Variational Auto-Encoder阅读笔记</a><a class="next" href="/2020/04/26/%E7%BD%91%E7%BB%9C%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E9%9B%86%E5%90%88/">网络异常检测数据集集合</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://lxzzhy.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Super-Resolution/">Super Resolution</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/anomaly-detection/">anomaly detection</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%9A%E9%A1%B9%E5%BC%8F/">多项式</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/05/01/%E5%85%B1%E8%BD%AD%E5%88%86%E5%B8%83/">共轭分布</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/30/importance-sampling/">importance sampling</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/28/A-summary-of-VAE-based-anomaly-detection/">A brief summary of VAE based anomaly detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/28/subderivative-%E6%AC%A1%E5%AF%BC%E6%95%B0/">subderivative-次导数</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/27/Network-Intrusion-Detection-Based-on-Semi-supervised-Variational-Auto-Encoder%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">Network Intrusion Detection Based on Semi-supervised Variational Auto-Encoder阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/27/Two-Stream-Action-Recognition-Oriented-Video-Super-Resolution-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/">Two-Stream Action Recognition-Oriented Video Super-Resolution 论文阅读报告</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/26/%E7%BD%91%E7%BB%9C%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E9%9B%86%E5%90%88/">网络异常检测数据集集合</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/26/variational-autoencoder/">variational autoencoder</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/26/one-hot-encoding/">one-hot encoding</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/22/FFT%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8F%92%E5%80%BC%E7%9A%84%E5%86%8D%E6%80%9D%E8%80%83/">FFT与多项式插值的再思考</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://www.cnblogs.com/heyuhhh/" title="神仙heyuhhh" target="_blank">神仙heyuhhh</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Sienna's blog..</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>